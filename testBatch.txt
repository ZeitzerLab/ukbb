#!/bin/bash
#SBATCH --time=1:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=16
#SBATCH --account=laraweed.guest
#SBATCH --partition=jzeitzer.guest
#SBATCH -O qe-%j
#SBATCH --mem-per-cpu=1
#SBATCH --job-name=test
#SBATCH --mem-per-cpu=1

# Set file paths
DATARAW = /scratch/groups/jzeitzer/UKBB/Data/Raw

DATACSV1 = /scratch/groups/jzeitzer/UKBB/Data/Outputs

DATACSV2 = /scratch/groups/jzeitzer/UKBB/Data/CSV

DATAIVIS = /scratch/groups/jzeitzer/UKBB/Data/IVIS

DATACOMM = /scratch/groups/jzeitzer/UKBB/Data/Commands

# Load modules
module purge

git clone https://github.com/activityMonitoring/biobankAccelerometerAnalysis.git

cd biobankAccelerometerAnalysis

bash utilities/downloadDataModels.sh

pip install --upgrade pip # Upgrades pip version if required

$ pip3 install --upgrade -r requirements.txt # Installs a known working set of dependencies, other package versions may also work

module load java

ml python/3.6.1

ml py-numpy/1.18.1_py36

ml py-scipy/1.4.1_py36

ml py-scikit-learn/0.24.2_py36

ml py-pandas/1.0.3_py36

ml R

javac -cp java/JTransforms-3.1-with-dependencies.jar java/*.java 

R

install.packages('nparACT', repos='http://cran.us.r-project.org')

q()


# Make sure directories exist
mkdir -p $DATARAW

mkdir -p $DATACSV1

mkdir -p $DATACSV2

mkdir -p $DATAIVIS

mkdir -p $DATACOMM




# Copy .cwa data to DATARAW from UKBB website or wherever it's stored





# Run Dwijen.py to get the commands necessary to covert .cwa to .csv 
cd DATACOMM
python3 /scratch/groups/jzeitzer/UKBB/Code/ukbb/generateProcessCommands.py





# loop to run jobs for converting each .cwa to .csv - run commands from Dwijen.py

cd DATACOMM

filename='processCmds.txt'
n=1
while read line; do
# reading each line
echo "srun $n : $line"
n=$((n+1))
done < $filename




# loop to run job that unzips .csv, runs nparACT, and rezips .csv 

cd DATACSV1  

for FILE in *.gz; do
    echo ${FILE}
    sbatch -n 1 -t 1-00:00 --wrap="gzip ${FILE}"
    sleep 1 # pause to be kind to the scheduler
done





